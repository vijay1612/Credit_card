## Predicting the result of Credit card applications using Logistic Regression

<p>Private, public and <em>a lot</em> Commercial banks process numerous credit card applications daily. Many of these applications are declined due to factors such as high loan balances, insufficient income, or multiple inquiries on a credit report. Manually evaluating these applications is time-intensive and prone to errors, leading to inefficiencies in decision-making. By leveraging machine learning techniques, banks can automate the approval process, ensuring accuracy, efficiency, and scalability. This notebook focuses on developing a machine learning model to predict credit card approvals, emulating the automation practices used in the banking industry.</p>

<p>I've used the <a href="http://archive.ics.uci.edu/ml/datasets/credit+approval">Credit Card Approval dataset</a> from the UCI Machine Learning Repository.<br>The structure of this notebook is as follows:</p>
<ul>
<li>First, I started off by loading and viewing the dataset.</li>
<li>The dataset has a mixture of both numerical and non-numerical features, that it contains values from different ranges, plus that it contains a number of missing entries.</li>
<li>Then, I preprocessed the dataset to ensure the machine learning model we choose can make good predictions.</li>
<li>After the data gets into good shape, I did some exploratory data analysis to build intuitions.</li>
<li>Finally, I built a machine learning model that can predict if an individual's application for a credit card will be accepted.</li>
</ul>

## Step-by-Step Process for predicting Credit Card Approval:

- First, loading and viewing the dataset. I found that since this data is confidential, the contributor of the dataset has anonymized the feature names.

- Then I tried to figure out the most important features of a credit card application. The features of this dataset have been anonymized to protect the privacy, but <a href="http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html">this blog</a> gives us a pretty good overview of the probable features. The probable features in a typical credit card application are <code>Gender</code>, <code>Age</code>, <code>Debt</code>, <code>Married</code>, <code>BankCustomer</code>, <code>EducationLevel</code>, <code>Ethnicity</code>, <code>YearsEmployed</code>, <code>PriorDefault</code>, <code>Employed</code>, <code>CreditScore</code>, <code>DriversLicense</code>, <code>Citizen</code>, <code>ZipCode</code>, <code>Income</code> and finally the <code>ApprovalStatus</code>. This gives a pretty good starting point, and we can map these features with respect to the columns in the output. </p>
<p>As we can see from our first glance at the data, the dataset has a mixture of numerical and non-numerical features. This can be fixed with some preprocessing.

- Then, I fixed some missing values for both numerical as well as non-numerical columns.

\*There is still some minor but essential data preprocessing needed before we proceed towards building our machine learning model. I divided these remaining preprocessing steps into three main tasks:

<ol>
<li>Convert the non-numeric data into numeric.</li>
<li>Split the data into train and test sets. </li>
<li>Scale the feature values to a uniform range.</li>
</ol>
<p>First, I converted all the non-numeric values into numeric ones. We do this because not only it results in a faster computation but also many machine learning models (like XGBoost) (and especially the ones developed using scikit-learn) require the data to be in a strictly numeric format. We will do this by using a technique called <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html">label encoding</a>.</p>

- After successfully converting all the non-numeric values to numeric ones, now, we will split our data into train set and test set to prepare our data for two different phases of machine learning modeling: training and testing. Ideally, no information from the test data should be used to scale the training data or should be used to direct the training process of a machine learning model. Hence, we first split the data and then apply the scaling.
<p>Also, features like <code>DriversLicense</code> and <code>ZipCode</code> are not as important as the other features in the dataset for predicting credit card approvals. We should drop them to design our machine learning model with the best set of features. In Data Science literature, this is often referred to as <em>feature selection</em>. </p>

- The data is now split into two separate sets - train and test sets respectively.

- <p>Essentially, predicting if a credit card application will be approved or not is a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> task. <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.names">According to UCI</a>, our dataset contains more instances that correspond to "Denied" status than instances corresponding to "Approved" status. Specifically, out of 690 instances, there are 383 (55.5%) applications that got denied and 307 (44.5%) applications that got approved. </p>
  <p>This gives us a benchmark. A good machine learning model should be able to accurately predict the status of the applications with respect to these statistics.</p>
  <p>Which model should we pick? A question to ask is: <em>are the features that affect the credit card approval decision process correlated with each other?</em> Although we can measure correlation, that is outside the scope of this notebook, so we'll rely on our intuition that they indeed are correlated for now. Because of this correlation, we'll take advantage of the fact that generalized linear models perform well in these cases. Let's start our machine learning modeling with a Logistic Regression model (a generalized linear model).</p>

- <p>We will now evaluate our model on the test set with respect to <a href="https://developers.google.com/machine-learning/crash-course/classification/accuracy">classification accuracy</a>. But we will also take a look the model's <a href="http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/">confusion matrix</a>. In the case of predicting credit card applications, it is equally important to see if our machine learning model is able to predict the approval status of the applications as denied that originally got denied. If our model is not performing well in this aspect, then it might end up approving the application that should have been approved. The confusion matrix helps us to view our model's performance from these aspects.  </p>

## Results:

<p><img src="//Users/vijju/Desktop/credit_card/.ipynb_checkpoints/Machine_Learning_project.ipynb/Screenshot 2024-12-30 at 12.12.14â€¯PM.png."></p><br>
<b>Accuracy of logistic regression classifier:</b>  0.8377192982456141</h3>
<b>Confusion matrix:</b>
 [[93 10]
 [27 98]]
 <b>From above screen shot you can conclude that the by performing RandomForest classifier the accuracy has been changed little bit and my final accuracy is:</b> 0.8552631578947368</h3>
